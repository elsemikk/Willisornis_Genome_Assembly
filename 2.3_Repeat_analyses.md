At this point, I have a curated set of consensus TE sequences. I will use this to see how much of the genome is taken up by TE sequences.

1) What proportion of the Genome is made up of different types of TEs?
2) How diverged are these TEs from their consensus sequence?

This is done most easily and conventionally using RepeatMasker.

```bash
#set up environment, obtaining TE library and genome sequence
mkdir /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/RepeatMasker
cd /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/RepeatMasker
cp /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/repeat_curation/Wilpoe_TE_library.lib .
cp /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/Willisornis_poecilinotus_JTW1144_700mill.fasta.gz ./Anteater700.fasta.gz
gunzip Anteater700.fasta.gz

#combine the species-specific library with previously-published, curated sequences to increase comprehensiveness
cat Wilpoe_TE_library.lib /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/repeat_curation/TEsorter/FicalbUracya_replibs.fasta > Wilpoe_FicUraRTE.lib
```

First, I am running repeatmasker with only my own library
```bash
#Run repeatmasker
conda activate RepeatMasker #version 4.0.9, with Dfam 3.1 installed, and NCBI/RMBLAST v2.6.0+
#RepeatMasker
time RepeatMasker -no_is -lib Wilpoe_TE_library.lib -dir . Anteater700.fasta -pa 23 -s -a -inv -gccalc -xsmall > Anteater700_rmask.log #slow search, more sensitive
#done
```
* `-a -inv`: output a .align file of alignments (-a), and make the orientation the same as the repeat consensus sequence, not the genome sequence (inv).
* `-s`: slow search, 0-5% more sensitive but slower.
* `-pa 23`: number of threads to use
* `-lib`: custom repeat library to use
* `-no_is`: do not search for bacterial inserts
* `-gccalc`: calculate gc content
* `--xsmall`: masked regions are given in lower case (soft masked) rather than hard masked

Now, we can parse the results of RepeatMasker and make a landscape graph using scripts from this github repository: https://github.com/4ureliek/Parsing-RepeatMasker-Outputs
```bash
#requires perl with bio::SeqIO
export PERLBREW_ROOT=/opt/perl5 #perlbrew will be installed in opt
/opt/perl5/bin/perlbrew switch perl-5.30.0 #A sub-shell is launched with perl-5.30.0 as the activated perl. Run 'exit' to finish it.

#parse the out file to find amount of DNA masked
time perl /home/0_PROGRAMS/Parsing-RepeatMasker-Outputs/parseRM.pl -i Anteater700.fasta.out -p -g 1089534386 -r Wilpoe_TE_library.lib -v

#parse the align file to make landscape graph
time perl /home/0_PROGRAMS/Parsing-RepeatMasker-Outputs/parseRM.pl -i Anteater700.fasta.align -g 1089534386 -r Wilpoe_TE_library.lib -m 0.0033 -l 100,1 -v
#done
```

**Timing**: When I ran with my old library: Normal search took 124m37s real time (1637m55 user; 779m39 sys) with a reduced library (no custom structure-based repeats). With the `-norna -nolow -div 40` it took 130m17 (1958m30, 673m42). Sensitive mode took 179m38 (2986m29 user, 646m53). Obviously, running on multiple cores is key or it will take days! Also, running on sensitive mode is clearly worth it as the extra time sacrifice is negligible (an hour) compared to the time it took to generate the library! Then, I made the new library based on EDTA and repeatmodeler on the new genome. It took real	634m50.415s; user	13860m53.005s; sys	532m42.479s (sensitive -s, -a) but I still want to curate it so this is not the final run. Parsing took real	102m37.025s; user	102m2.389s; sys	0m28.188s. Landscaping took real	84m57.432s; user	84m18.842s; sys	0m35.410s.  
Finally, with my curated library it took: 126m59 (1653m37 user) for RepeatMasker

Now I am adding in the previous libraries for Ficedula and Uraeginthus.
```bash
conda activate RepeatMasker #version 4.0.9, with Dfam 3.1 installed, and NCBI/RMBLAST v2.6.0+
time RepeatMasker -no_is -lib Wilpoe_FicUraRTE.lib -dir . Anteater700.fasta -pa 23 -s -a -inv -gccalc -xsmall > Anteater700_rmask_WilpoeFicUraRTE.log #slow search, more sensitive

#requires perl with bio::SeqIO
export PERLBREW_ROOT=/opt/perl5 #perlbrew will be installed in opt
/opt/perl5/bin/perlbrew switch perl-5.30.0 #A sub-shell is launched with perl-5.30.0 as the activated perl. Run 'exit' to finish it.

#parse the out file to find amount of DNA masked
time perl /home/0_PROGRAMS/Parsing-RepeatMasker-Outputs/parseRM.pl -i Anteater700.fasta.out -p -g 1089534386 -r Wilpoe_FicUraRTE.lib -v

#parse the align file to make landscape graph
time perl /home/0_PROGRAMS/Parsing-RepeatMasker-Outputs/parseRM.pl -i Anteater700.fasta.align -g 1089534386 -r Wilpoe_FicUraRTE.lib -m 0.0033 -l 100,1 -v

#use % divergence instead of my divergence
time perl /home/0_PROGRAMS/Parsing-RepeatMasker-Outputs/parseRM.pl -i Anteater700.fasta.align -g 1089534386 -r Wilpoe_FicUraRTE.lib -l 100,1 -v
#done

```
* `-i`: "RepeatMasker output .out or RepeatMasker output .align (use -d and provide a directory path here to parse several files) Use of .align is best for -l, because the %div corrected for higher mutation rate at CpG sites and the Kimura 2-Parameter divergence metric is in the .align files (thus, the graphs are smoother) However, the script will treat separately repeats that overlap (merged in the .out, with one name kept): this means that for -p, the amount of DNA masked by each of the repeats will be much higher than if a .out file is parsed.
* `-p`: PARSING: "Use -p to get a summary of the masking, as well as amount or DNA, counts of fragments, etc, for each repeat name (all-repeats file), family, class and total amount (summary file), if sequence names were formatted as per RepeatMasker nomenclature: Rname#Rclass/Rfamily, or at least Rname#Rclass (Rfamily will equal Rclass if no / ). To get a summary file with number of counts, average length, number of reconstructed repeats, total length annotated as each repeat, etc. The options below are only relevant if this is chosen. Note that for a .align, the median is not really median, since it is done by position, which is why it is skipped"
* `-l`: LANDSCAPE: "Use -l <max,bin> to set behavior to split the amount of DNA by bins of %div or My, allowing to generate landscape graphs for each repeat name, family or class. To generate additional outputs that can be used to make landscape graphs by repeat, by family and by class (3 files). Two values should be given, separated by a comma: `<max>,<bin> <max>` is the value of the last bin, where everything higher than this %div or My will be placed `<bin>` is the size of the bins. If -m is set, then numbers here HAVE TO BE in My instead of %divergence. Typically: -l 50,1 (if %div are corrected for CpGs then values tend to be higher) See the end of this help for more examples." Note: Kapusta&Suh 2017 used 1 MY bins to a max of 100 MYA
* `-m`: "To output bins in My and not %div: substitution rates need to be provided: if -d not chosen, use -m substitution_rate (ex. -m 0.00199) if -d is chosen, then different values can be provided for each input files, if you use -m subst-rates.tab, and subst-rates.tab is a file with 2 columns: filename_as_in_dir \\t substitution_rate" Note: 3.3e-3 was estimated for Passeriformes by Zhang et al 2014
* `-a`: "AGE SPLIT: Set -a to set behavior to determine the amounts of DNA in a genome that is masked by repeats of different lineages / %divergence categories." Option1: load a file. File should contain TE age data, tabular delimited. Columns should be: Rname \\t Rclass \\t Rfam \\t Lineage. The Rname needs to be an exact match to the repeat names in the RM output; class and family can be changed. If -d is chosen, the file must contain info for ALL repeats of all files. Option2: 1 or 2 values (INT or FLOAT). Use a comma to sepearate 2 values; their order does not matter (-a 13.5,15 and -a 15,13.5 are equivalent). Any DNA masked with %div < the smallest number given (here 13.5) will be placed as lineage specific. Any DNA masked with %div > the largest number given (here 15) will be placed as ancient, and the rest will be placed as \"nd\". If -m is set, then numbers here HAVE TO BE in My instead of %divergence. If -d is chosen and different values should be used for each input files you can provide a file containing 2 columns: filename \\t X filename = name of the file to be parsed X = the value (in nt)
* `-f`: If the file THAT WAS MASKED, typically a genome, is in the same directory as the .out or .align file(s). If not provided, the % of genome masked won't be calculated. Names should correspond before .align and .fa(sta), and/or .out and .fa(sta), for ex: '-i hg38.out -f' will look for hg38.fa and 'hg38.out_RM405_RB20140131 -f' will also look for hg38.fa
* `-g`: Alternatively to genome file(s), you can provide the total length of the genome (in nt) If several genomes are being looked at (-d chosen for example) this can be a file, containing 2 columns: filename \\t X filename = name of the file to be parsed X = the value (in nt)
* `-n`: To remove Ns from the genome file before getting its length (to calculate the percentages on the amount of DNA that is not Ns)
* `-r`: To add the length of the consensus sequence included in the output, set here the library of consensus sequences used to mask the genome. If several maskings are parsed, you can concatenate the different libraries (same if RM was run with -lib, concatenate the RM library and the user one) If a repeat could not be found, or if -r is not chosen, the value in the output will be \"nd\". 
* `-v`: verbose

**Timing**: took 83m56 on 1 thread to parse, 71m18 to to the landscape analysis.

# Results
Settings|Percent masked|SINEs|LINEs|LTRs|DNA|Unclassified|Total interspersed|Satellites|Simple repeats|Low Complexity|
---|---|---|---|---|---|---|---|---|---|---|
Only custom structure-based TE library, old assembly|8.66|0|0|2.55|5.29|0.94|8.78|NA|NA|NA|
No custom structure-based TE library | 8.01|0.09|4.71|1.07|0.03|0.90|6.81|0.10|0.88|0.23
Normal|11.01|0.03|3.30|2.43|2.57|1.63|9.96|0.11|0.84|0.22|
Sensitive search|11.10|0.03|3.33|2.45|2.62|1.65|10.07|0.11|0.84|0.22|
-norna -nolow -div 40 |10.01|0.03|3.31|2.44|2.61|1.63|10.02|0.11|NA|NA|
sensitive search, new library|13.29|0.10|4.10|2.05|3.93|2.28|12.46|0.11|0.83|0.21|
sensitive search, Curated new library|9.76|0.31|4.62|3.41|0.00|0.30|8.64|0.01|0.88|0.22|
sensitive search, Curated new library + Ficalb/Uracya|10.04|0.32|4.82|3.46|0|0.29|8.89|0.06|0.88|0.22|

# reportable data
In the paper, I am reporting the fraction of the genome masked by each repeat class/family.  
To turn bp in fraction, I am using the length of the genome with runs of N's removed (since these do not represent real sequence that could be masked). This is conveniently reported in Anteater700.fasta.tbl produced by repeatmasker: `total length: 1112597196 bp  (1089534386 bp excl N/X-runs)`.
* 98981641/1089534386 =  9.084765223% masked
* 53722713/1089534386 =  4.930795548% LINE
* 3570874/1089534386 =  0.32774312% SINE
* 3275380/1089534386 = 0.300621994 Unknown
* 38412674/1089534386 = 3.52560456 LTR

Then, I am using the parsed file from Parsing-RepeatMasker-Outputs/parseRM.pl (with `Wilpoe_FicUraRTE.lib`) to get number of basepairs masked by each family and class of repeat. All the unknowns are lumped into one number so to get the unknowns for LTR vs LINE I just subtract the identified LTR/LINE families from their respective totals to get the unknowns for each class.
The other libraries use a different classification system using the name ERV3 instead of ERVL and ERV2 instead of ERVK so a I am adding those two values together for those two families.

I have placed `Anteater700.fasta.tbl` and all the landscape files into the Repeat_library folder of this repository.

# Plot the landscape
I am plotting the landscape plot in R using the data Anteater700.fasta.align.landscape.Div.Rclass.tab.
```R
#set working directory
setwd("~/Downloads") #cd into the folder containing the landscape data

#load required libraries
library(tidyr)
library(stringr)
library(ggplot2)
library(dplyr)
#library(multcomp)

#load the landscape data
landscape <- read.table("Anteater700.fasta.align.landscape.Div.Rclass.tab", skip=1)

#
landscape <- landscape %>%
  slice(-1) %>%
  #group_by(V1)
  #gather(key = Timestep, value= Value, V2:V101) 
  select(V1:V179) %>%
  gather(key = Timestep, value= Value, V2:V179) #for %Div 
  
#remove the letter V from the column 2 values to make it numeric, and subtract 1 to make it start at 1
landscape <- landscape %>%
  separate(Timestep, into=c("drop", "Timestep"), sep=1) 
landscape <- landscape[,-2]
landscape[,2] <- as.numeric(as.numeric(landscape[,2]) - 1)

#make the values numeric
landscape$Value <- as.numeric(landscape$Value)

#divide timestep by 4 to reflect the length of the timesteps in this data
landscape$Timestep<- landscape$Timestep*0.25

#plot the data. This is Figure 1.
ggplot(landscape, aes(x=Timestep, y=Value, fill=V1))+
  #geom_bar(position="dodge", stat="identity")+
  geom_bar(stat="identity")+
  xlim(0,45)+
  #theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),)+ 
  theme_classic()+
  #scale_fill_manual(values = c("#29924a", "#9d0b0b", "#46b3e6", "#fccf4d"))+
  scale_fill_manual(values = c("#29924a", "#125ca4", "#5d3997", "#8ac9c9", "#218b8c", "#b21218"))+
  xlab("Divergence from Consensus (%)") +
  ylab("Frequency") +
  #ggtitle("Divergence landscape of Transposable Elements in Willisornis")+
  #theme(plot.title = element_text(size = 16, hjust=0.5))+
  #facet_grid(. ~ V1)+
  facet_wrap(~ V1)+
  theme(legend.position = "none")
```

I placed this plot, and a comparison plot with the uncurated data, into the Repeat_Library folder.

# how much did curation lengthen TE's?
I want to calculate how much longer curation made the consensus sequences relative to their original state.
```bash
# get lengths of input library
cat Anteater_curated_TE_library_consensus.95.fasta | grep "^>" | sed 's/^>//g' | while read line ; do awk -v seq="$line" -v RS='>' '$1 == seq {print RS $0}' Anteater_repeat_library_95.lib.safe | awk '/^>/{if (l!="") print l; print; l=0; next}{l+=length($0)}END{print l}' | grep -v ">" >> original_consensus_lengths ; done

/home/0_PROGRAMS/seqtk/seqtk subseq Anteater_repeat_library.lib Wilpoe_Te_naming_table.txt
cat Wilpoe_Te_naming_table.txt | cut -f 1 | sed 's/\//@/g' | while read line ; do awk -v seq="$line" -v RS='>' '$1 == seq {print RS $0}' Anteater_repeat_library_95.lib.safe | awk '/^>/{if (l!="") print l; print; l=0; next}{l+=length($0)}END{print l}' | grep -v ">" >> original_consensus_lengths ; done

# get lengths of new library
awk '/^>/{if (l!="") print l; print; l=0; next}{l+=length($0)}END{print l}' Wilpoe_TE_library.fasta | grep -v "^>" > curated_consensus_lengths

#use R to calculate
R
og <- read.table("original_consensus_lengths")
cur <- read.table("curated_consensus_lengths")
perc <- cur/og
sum(perc)/nrow(perc) #2.750581
```
Curation increased the length of consensus sequences by 2.750581 times on average.
