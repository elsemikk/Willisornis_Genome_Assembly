

We can use kmers to estimate the genome size and heterozygosity of our genome.

## *What is a kmer?*
Basically, for any number k, a kmer is a unique sequence of nucleotides which is k basepairs long. For example, ACG is a 3mer and ACT is another 3mer. ACTGTGTACGA is an 11mer. It happens to contain eight 3mers:ACT, CTG, TGT, GTG, GTA, TAC, ACG, and CGA. All those 3mers occur once except for TGT which ocurrs twice. 
The higher the value of k, the more possible unique kmers exist. Which kmer you choose to assess will depend on how long your reads are, and your depth of coverage. Generally, you want longer kmers if you can use them, but with shorter reads you need smaller kmers.


We can estimate genome size by looking at the distributions of kmers. Kmer spectra are explained [here](https://kat.readthedocs.io/en/latest/kmer.html).

## Counting kmers with Jellyfish

Jellyfish can be used to count the frequency of kmers in sequencing data, and these counts can be used by other kmer programs. 

There are a couple tutorials on estimating genome size with [Jellyfish](https://github.com/gmarcais/Jellyfish/tree/master/doc#info).  
Here is an example of a Jellyfish [pipeline](https://github.com/venta380/Leptidea-Genome-size-scripts/blob/master/jellyfish.sh). Here are a [couple](http://koke.asrc.kanazawa-u.ac.jp/HOWTO/kmer-genomesize.html) similar [tutorials](https://bioinformatics.uconn.edu/genome-size-estimation-tutorial/#).

```bash
#set up environment
cd /home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/genome

export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/hhome/$USERNAME/tools/jellyfish-2.3.0/lib #when running from node b where hhome = home, need to respecify location of lib.
export PATH=$PATH:~/tools/kmergenie-1.7051/
export PATH=$PATH:~/tools/jellyfish-2.3.0/bin/

#17ners
#count kmers, with quality filters - I found this gave me much better reults with my skuas (fewer false kmers)
time jellyfish count -t 23 -m 17 -s 8G -t 23 -C --min-quality=20 --quality-start=33 -o kmers/anteaters_q17mers.jf <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L006_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L006_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L007_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L007_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L002_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L002_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L003_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L003_R2_001.fastq.gz) 

#compute a histogram of kmer frequency, with quality filters (needed for genomescope)
time jellyfish histo -o kmers/anteater_q17mers_jf.hist -f kmers/anteaters_q17mers.jf

#25mers
#count kmers, with quality filters - I found this gave me much better reults with my skuas (fewer false kmers)
time jellyfish count -t 23 -m 25 -s 8G -t 23 -C --min-quality=20 --quality-start=33 -o kmers/anteaters_q25mers.jf <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L006_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L006_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L007_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S5_L007_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L002_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L002_R2_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L003_R1_001.fastq.gz) <(gunzip -c fltrd_adaptrlss4717-JW-0008_S4_L003_R2_001.fastq.gz) 

#compute a histogram of kmer frequency if wanted
time jellyfish histo -o kmers/anteater_q25mers_jf.hist -f kmers/anteaters_q25mers.jf

```
* `-t`: number of threads to use
* `-m 25` length of kmer to analyse. Longer gives better resolution between kmers but reduces coverage. I used kmer genie to decide this value.
* `-s`: size of hash table. I estimated as s=G+Gcek = 1.4Gb + (1.4Gb * 60 * 73 * 0.01) = 62.7G where G = genome size, k = kmer length, e = illumina error rate, c = estimated coverage.
* `-C`: canonical, look at both forward and reverse strand.
* `--min-quality=20`: quality filter the reads: this should reduce calling false kmers due to sequencing errors at low-quality bases
* `-o`: output name
* `gunzip -c`: uncompress the compressed .gz files as you go
* `-f`: file for histo to read (output of count)
* `<(gunzip -c.....)`: this is a cool trick to let the program use fastq.gz files when it only accepts .fastq files. It gunzips the file within the command so that jellyfish gets the uncompressed input but you do not have to actually have the uncompressed file.

**Timing**:
sample|real time|user time|system time|threads|
---|---|---|---|---|
CISK_3|13m17s|106m24s|3m23s|8|
Anteater K25|24m19|319m3|6m13|
Anteater K17|20m34|308m16|5m12|

The histo function only takes 2-7 mins to run on the output, with 1 thread.

We can get a preliminary look at the results in R and roughly estimate genome size. It will take seconds. I would not report these estimates in a manuscript though as the method is more crude than other programs (genomescope, kmer genie, KAT, etc) that estimate genome size from kmers.
```R
sample <- c("anteater")

#cycle through i to pick each sample. You could put it into a loop but I did not because I was running each sample at different times while waiting for the jellyfish results.

i=1
setwd(paste0("/home/0_GENOMES1/0_WEIRLAB_GENOMES_CHROMIUMX/anteater/genome/kmers"))
spec1_17 <- read.table(paste0(sample[i],"_q17mers_jf.hist")) #read the histogram data
plot.new()
plot(spec1_17[1:50,],type="l", xlab="frequency", ylab="number of kmers", main=sample[i])

#Record the location of the peak and inflection point. 
peak=36
inflection=9

#calculate "genome size".
sum(as.numeric(spec1_17[(inflection+1):nrow(spec1_17),1]*spec1_17[(inflection+1):nrow(spec1_17),2]))/peak
```
**Results**:

sample|peak|inflection|rough genome size (bp)|
---|---|---|--|
CISK_3|9|3|1,526,842,782|
Anteater 25mers|30|7|1,305,936,084|
Anteater 17mers|36|9|1,233,405,320|
If there is [no peak in kmer frequency](http://seqanswers.com/forums/showthread.php?t=41874) then you might have pretty low coverage...

Choice of kmer affects these...

# Kmer Analysis Toolkit: GC content
KAT can more accurately estimate genome size, and also assesses GC content of kmers.
```bash 
conda activate kmers
time kat hist -o anteater_q17mers_kat.hist -v anteaters_q17mers.jf #if you just want to use the jellyfish results

time kat gcp -o anteater_17mers_kat.gcp -m 17 -t 23 -v anteaters_q17mers.jf
#make a better plot by controlling axes
kat plot density -o anteater_17mers_kat.gcp_plotted -t "Coverage vs GC count of 17-mers" -a "17-mer frequency" -b "GC count" -y "17" -x "100" anteater_17mers_kat.gcp.mx
```
kat hist on k25 took 15m19 on 1 thread (13m52 user).
* peaks: 4
* global minima: 6X
* global maxima: 28X
* estimated genome size: 1.18625 Gb
* Heterozygous rate: 0.59%

The results are archived in QC_Reports/kmer_analysis
**Timing**: kat gcp took 4m47 (19m54 user), plotting is very fast.

First, we take a look at the kat_gcp.mx.png plots. We see ones where a GC smear at the error kmers of frequency 1, and a tighter blob of the real kmers centred around a GC content of 7-8 out of 17 bp.

Now we can summarise the results with multiQC
```bash
conda activate fastqc
multiqc . -n Anteater_kmer_QC
```

Conclusion:  

My assembly is 1,112,597,196 including N's. KAT estimated that it is 1.1-1.2 Gb which is quite close! Supernova estimated 1.4 Gb, but I have noticed that supernova estimates always seem too high with other passerine genomes.

Method|Genome Size Estimate|"Assembly completeness"|
---|---|---|
KAT (25mer)|1,186,253,834|93.79%|
KAT (17mer)|1,091,438,929|>100%|
Supernova|1,400,000,000|
