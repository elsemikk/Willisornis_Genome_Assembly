# Running Maker

Here are instructions for running the Maker genome annotation program. Detailed tutorials can be found on the maker wiki [here](http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/MAKER_Tutorial_for_WGS_Assembly_and_Annotation_Winter_School_2018).  
There are alsp some nice tutorials [here](https://reslp.github.io/blog/My-MAKER-Pipeline/) and [here](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2).  

The data we are using as input for maker are:  
1) Genome sequence (Fasta file, this species)
2) RNA sequences (Fasta file, same or closest possible species)
3) protein sequences (Fasta file, related species)
4) Repeat library

First, gather the required data:
### Genome Sequence
```bash
cp ~/Willisornis/Genome/Willisornis_poecilinotus_JTW1144_FASTAOUTPUT.fasta Willisornis_input.fasta
#actually, I transferred my genome sequence as a zipped file to be easier to transfer to the supercomputer
#below, I did
gunzip Willisornis_input.fasta.gz
nano Willisornis_input.fasta #be patient, it will take a while to load. Don't press anything.
#Use the arrow keys to scroll right, and change the name of the first line from ">0" to ">0start"
#press ctrl-o to save, then ctrl-x to exit
#check that it worked ok
less Willisornis_input.fasta #all good, press q to quit.
```
**IMPORTANT**: If your first contig is named "0", you needed to rename contig "0" to "0start" because maker cannot handle contigs named "0".

### Transcriptome data
*Manacus vitellinus* transcriptome from RNA-seq reads.
```bash
cp ~/Genetic_resources/Manacus_RNA/trinity_out_dir/Trinity.fasta ManacusRNA_input.fasta
```

### Proteome data
The Maker wiki recommends against the use of UniProt proteomes [here](http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained):
>In most annotations there are a number of weakly supported genes that are often dead transposons or pseudogenes, so I do not like to take all the annotated proteins from a related species. In the worst cases scenario imagine you have a dead transposon from a closely related species, when you made your repeat masking library you found that one the entries matched this sequence. Assuming that it is a real gene you delete it from your masking library. Now when you annotate the genome this one gene becomes a whole gene family in the annotation set but is really a combination of bad evidence and bad masking.

so, we could just use the SwissProt data base, which we downloaded previously with these commands:
```bash
cd Genetic_resources 
wget ftp://ftp.uniprot.org/pub/databases/uniprot/current_release/knowledgebase/complete/uniprot_sprot.fasta.gz
gunzip uniprot_sprot.fasta.gz
cd ~/Willisornis/maker
cp ~/Genetic_resources/uniprot_sprot.fasta Swissprot_input.fasta
```

However, I would like to supplement this with a few higher quality bird proteomes, which I previously filtered to remove repetitive elements during the repeatmasker step, when I made `RefAves_proteins_no_tes.fa`. To further filter, I will remove anything labelled "Uncharacterized protein". And then concatenate it with SwissProt.
```bash
awk '/^>/ {P=index($0,"Uncharacterized protein")==0} {if(P) print} ' RefAves_proteins_no_tes.fa > RefAves_proteins_no_teups.fa
cat Swissprot_input.fasta RefAves_proteins_no_teups.fa > Willisornisprot_input.fasta
```

### Repeat library

```bash
cp ~/Willisornis/RepeatMasking/Willisornis_repeat_library_cleaned_withFicalbUracya.lib Willisornisreps_input.fasta
```

## Control Files
To run maker you need three input files:  
1) maker_exe.ctl: - paths to required programs  
2) maker_bopt.ctl: BLAST and Exonerate settings  
3) maker_opt.ctl: other MAKER settings as location of genome, and training parameters for gene prediction programs.  

Templates of all three files can be created in your working directory with a single command. It works best if all prerequisite programs are already loaded into PATH, because then they will be automatically detected and their paths written into the control file, otherwise you will need to write them manually.
```bash
maker -CTL
```

Open maker_exe.ctl and verify that all paths are correct. When I made it on the server there was an error in mine: it detected the path to snap as usr/bin/snap, but that is the wrong snap program! Now that I am running on the Scinet there are a mix of paths, some to the Scinet installed programs and some that I installed myself.

It looks like this in the end. Note I am not specifying paths to programs I will not use (fgenesh (costs money, won't use), gmhmmp (for prokaryotes, we are doing a eukaryote), or blasta and xdformat (WUblast, we are using NCBI blast instead), or formatdb&blastall (old version of NCBI BLAST)).  

```
#-----Location of Executables Used by MAKER/EVALUATOR
makeblastdb=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/blast+/2.7.1/bin/makeblastdb #location of NCBI+ makeblastdb executable
blastn=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/blast+/2.7.1/bin/blastn #location of NCBI+ blastn executable
blastx=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/blast+/2.7.1/bin/blastx #location of NCBI+ blastx executable
tblastx=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/blast+/2.7.1/bin/tblastx #location of NCBI+ tblastx executable
formatdb= #location of NCBI formatdb executable
blastall= #location of NCBI blastall executable
xdformat= #location of WUBLAST xdformat executable
blasta= #location of WUBLAST blasta executable
RepeatMasker=/gpfs/fs0/path/to/folder/tools/RepeatMasker/RepeatMasker #location of RepeatMasker executable
exonerate=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/exonerate/2.4.0/bin/exonerate #location of exonerate executable

#-----Ab-initio Gene Prediction Algorithms
snap=/gpfs/fs0/path/to/folder/tools/snap/snap #location of snap executable
gmhmme3=/path/to/folder/tools/gm_et_linux_64/gmhmme3 #location of eukaryotic genemark executable
gmhmmp= #location of prokaryotic genemark executable
augustus=/gpfs/fs0/path/to/folder/tools/Augustus/bin/augustus #location of augustus executable
fgenesh= #location of fgenesh executable
tRNAscan-SE=/gpfs/fs0/path/to/folder/tools/tRNAscan-SE-2.0/tRNAscan-SE #location of trnascan executable
snoscan=/gpfs/fs0/path/to/folder/tools/snoscan-0.9.1/snoscan #location of snoscan executable

#-----Other Algorithms
probuild= #location of probuild executable (required for genemark)
```

Program|Version|
---|---|
BLAST+|2.7.1|
RepeatMasker|4.1.0|
Exonerate|2.4.0|
snap|2006-07-28|
augustus|3.3|
tRNAscan-SE|2.0|
snoscan|0.9.1|

Next, open maker_bopt.ctl. Make sure that blast_type=ncbi+ ; we will use default settings for the rest.

```
#-----BLAST and Exonerate Statistics Thresholds
blast_type=ncbi+ #set to 'ncbi+', 'ncbi' or 'wublast'

pcov_blastn=0.8 #Blastn Percent Coverage Threhold EST-Genome Alignments
pid_blastn=0.85 #Blastn Percent Identity Threshold EST-Genome Aligments
eval_blastn=1e-10 #Blastn eval cutoff
bit_blastn=40 #Blastn bit cutoff
depth_blastn=0 #Blastn depth cutoff (0 to disable cutoff)

pcov_blastx=0.5 #Blastx Percent Coverage Threhold Protein-Genome Alignments
pid_blastx=0.4 #Blastx Percent Identity Threshold Protein-Genome Aligments
eval_blastx=1e-06 #Blastx eval cutoff
bit_blastx=30 #Blastx bit cutoff
depth_blastx=0 #Blastx depth cutoff (0 to disable cutoff)

pcov_tblastx=0.8 #tBlastx Percent Coverage Threhold alt-EST-Genome Alignments
pid_tblastx=0.85 #tBlastx Percent Identity Threshold alt-EST-Genome Aligments
eval_tblastx=1e-10 #tBlastx eval cutoff
bit_tblastx=40 #tBlastx bit cutoff
depth_tblastx=0 #tBlastx depth cutoff (0 to disable cutoff)

pcov_rm_blastx=0.5 #Blastx Percent Coverage Threhold For Transposable Element Masking
pid_rm_blastx=0.4 #Blastx Percent Identity Threshold For Transposbale Element Masking
eval_rm_blastx=1e-06 #Blastx eval cutoff for transposable element masking
bit_rm_blastx=30 #Blastx bit cutoff for transposable element masking

ep_score_limit=20 #Exonerate protein percent of maximal score threshold
en_score_limit=20 #Exonerate nucleotide percent of maximal score threshold
```

Open maker_opts.ctl. There is a good explaination of all the options [here](http://weatherby.genetics.utah.edu/MAKER/wiki/index.php/The_MAKER_control_files_explained).

The settings we will change are:  
* genome=Willisornis700_input.fasta
* altest=Manacus_RNA.fasta
  * Since our data is from a different species, we will use the altest setting instead of the est setting (it will use the slower tBlastx)
* protein=Willisornisprot_input.fasta
* rmlib=Willisornisreps_input.fasta
* repeat_protein=/gpfs/fs0/path/to/folder/tools/maker/data/te_proteins.fasta
* est2genome=1
* protein2genome=1 
* trna=0  
* cpus=10
* max_dna_len=100000
* min_contig=10000

```
#-----Genome (these are always required)
genome=Willisornis_input.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)
organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic

#-----Re-annotation Using MAKER Derived GFF3
maker_gff= #MAKER derived GFF3 file
est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no
altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no
protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no
rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no
model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no
pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no
other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no

#-----EST Evidence (for best results provide a file for at least one)
est= #set of ESTs or assembled mRNA-seq in fasta format
altest=ManacusRNA_input.fasta #EST/cDNA sequence file in fasta format from an alternate organism
est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file
altest_gff= #aligned ESTs from a closly relate species in GFF3 format

#-----Protein Homology Evidence (for best results provide a file for at least one)
protein=Willisornisprot_input.fasta  #protein sequence file in fasta format (i.e. from mutiple oransisms)
protein_gff=  #aligned protein homology evidence from an external GFF3 file

#-----Repeat Masking (leave values blank to skip repeat masking)
model_org=all #select a model organism for RepBase masking in RepeatMasker
rmlib=Willisornisreps_input.fasta #provide an organism specific repeat library in fasta format for RepeatMasker
repeat_protein=/gpfs/fs0/path/to/folder/tools/maker/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner
rm_gff= #pre-identified repeat elements from an external GFF3 file
prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no
softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)

#-----Gene Prediction
snaphmm= #SNAP HMM file
gmhmm= #GeneMark HMM file
augustus_species= #Augustus gene prediction species model
fgenesh_par_file= #FGENESH parameter file
pred_gff= #ab-initio predictions from an external GFF3 file
model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)
est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no
protein2genome=1 #infer predictions from protein homology, 1 = yes, 0 = no
trna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no
snoscan_rrna= #rRNA file to have Snoscan find snoRNAs
unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no

#-----Other Annotation Feature Types (features MAKER doesn't recognize)
other_gff= #extra features to pass-through to final MAKER generated GFF3 file

#-----External Application Behavior Options
alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases
cpus=10 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)

#-----MAKER Behavior Options
max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)
min_contig=10000 #skip genome contigs below this length (under 10kb are often useless)

pred_flank=200 #flank for extending evidence clusters sent to gene predictors
pred_stats=0 #report AED and QI statistics for all predictions as well as models
AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)
min_protein=0 #require at least this many amino acids in predicted proteins
alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no
always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no
map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no
keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)

split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)
single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no
single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'
correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes

tries=2 #number of times to try a contig if there is a failure for some reason
clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no
clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no
TMP= #specify a directory other than the system default temporary directory for temporary files
```

# Move onto Niagara
```bash
#log into Niagara supercomputer and make a folder for the annotation
scp $USERNAME@[IP Address Goes Here]:~/Willisornis/Maker2/* . #transfers all files in this folder onto othe supercomputer
#everything should say 100% done
gunzip Willisornis_input.fasta.gz
nano Willisornis_input.fasta #be patient, it will take a while to load. Don't press anything.
#Use the arrow keys to scroll right, and change the name of the first line from ">0" to ">0start"
#press ctrl-o to save, then ctrl-x to exit
#check that it worked ok
less Willisornis_input.fasta #all good, press q to quit.

#We will split the genome into chunks to run on each chunk separately.
fasta_tool --chunk 100 Willisornis_input.fasta #this tool comes with maker, in the folder maker/bin.
#created 64 chunks labelled 000 to 063
```

split data into chunks and run maker individually on chunks with 1 chunk per node and cores for blast set to 40

# Setup environment and run maker!

This is the script used to run maker. It loads all the required packages that are preinstalled, as well as putting some programs into path that I installed myself. It has to have 16 input files.

```bash
cat > Niagara_submitfile_Willisornismaker_chunk01.sh
```

```
#!/bin/bash
#SBATCH --nodes=1 #
#SBATCH --ntasks-per-node=1#
#SBATCH --cpus-per-task=40
#SBATCH --mem=0 #set to 0 to use all available memory of each requested node. Advatage, any of the ntasks of each node can use any amount of the memory provided to sum does not exceed thata available to the node
#SBATCH --time=13:00:00
#SBATCH --job-name Willisornis_Maker_Round1
#SBATCH --output=OUTPUT_R1_01_%.txt

#export paths
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/RepeatMasker 
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/snap 
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/snap/Zoe 
export ZOE=/gpfs/fs0/path/to/folder/tools/snap/Zoe
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/exonerate-2.2.0-x86_64/bin
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/maker/bin
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/snoscan-0.9.1
export PATH=$PATH:/gpfs/fs0/path/to/folder/tools/tRNAscan-SE-2.0
export LD_PRELOAD=/cvmfs/soft.computecanada.ca/easybuild/software/2017/avx512/Compiler/gcc7.3/openmpi/3.1.2/lib/libmpi.so

#load modules
module load NiaEnv
module load CCEnv
module load StdEnv
module load intel/2019.3
module load nixpkgs/16.09
module load gcccore/.8.3.0
module load gcc/7.3.0
module load perl/5.22.4
module load bioperl/1.7.1 #1.7.5
module load exonerate/2.4.0
module load trf/4.09
module load rmblast/2.9.0
module load blast+/2.7.1
module load openmpi/3.1.2
module load augustus/3.3
export PATH=/gpfs/fs0/path/to/folder/tools/Augustus/bin::/gpfs/fs0/path/to/folder/tools/Augustus/scripts:$PATH
export AUGUSTUS_CONFIG_PATH=/gpfs/fs0/path/to/folder/tools/Augustus/config/
 
export OMP_NUM_THREADS=40

#User sets these options
WD=/path/to/folder/0_MAKER/Willisornis

#automated code to run (don't change)
   cd $WD
   #job1
   (maker -cpus 10 -base Willisornis_input -g Willisornis_input_000.fasta) &
   (maker -cpus 10 -base Willisornis_input -g Willisornis_input_001.fasta) &
   (maker -cpus 10 -base Willisornis_input -g Willisornis_input_002.fasta) &
   (maker -cpus 10 -base Willisornis_input -g Willisornis_input_003.fasta) &
wait
```

Now copy the input file 16 times to run in 16 batches. I was just learning bash at this point, this is not the best way to do this task.
```bash
cat > nums.txt
```
```
02
03
04
05
06
07
08
09
10
11
12
13
14
15
16
```
```bash
#make 16 copies of the input file
cat nums.txt | while read line ; do cat Niagara_submitfile_Willisornismaker_chunk01.sh | sed "s/OUTPUT_R1_01/OUTPUT_R1_$line/g" | sed "s/job1/job$line/g" > Niagara_submitfile_Willisornismaker_chunk"$line".sh ; done 
#Now I went in by hand editing the input fasta files to go up from 000 to 063 with 4 per file.
```

```bash
chmod +x ./*.sh #make executable!
```
Then submit all the batch files to Niagara!
```bash
sbatch Niagara_submitfile_Willisornismaker_chunk01.sh

sbatch Niagara_submitfile_Willisornismaker_chunk02.sh

sbatch Niagara_submitfile_Willisornismaker_chunk03.sh

sbatch Niagara_submitfile_Willisornismaker_chunk04.sh

sbatch Niagara_submitfile_Willisornismaker_chunk05.sh

sbatch Niagara_submitfile_Willisornismaker_chunk06.sh

sbatch Niagara_submitfile_Willisornismaker_chunk07.sh

sbatch Niagara_submitfile_Willisornismaker_chunk08.sh

sbatch Niagara_submitfile_Willisornismaker_chunk09.sh

sbatch Niagara_submitfile_Willisornismaker_chunk10.sh

sbatch Niagara_submitfile_Willisornismaker_chunk11.sh

sbatch Niagara_submitfile_Willisornismaker_chunk12.sh

sbatch Niagara_submitfile_Willisornismaker_chunk13.sh

sbatch Niagara_submitfile_Willisornismaker_chunk14.sh

sbatch Niagara_submitfile_Willisornismaker_chunk15.sh

sbatch Niagara_submitfile_Willisornismaker_chunk16.sh
```

Now I check where there are in the queue. Mine are job IDs 2111171-86 submitted Nov 25 2019 at about 3:08 pm.
```
squeue -u $USER
squeue --start -j JOBID
```

**What is hapenning**:  
First, it will mask the genome using RepeatMasker and RepeatRunner. Complex repeats are hard masked while simple repeats are soft masked.    
Then, it will use RNA and protein information. Since our RNAs are from a different species and may have diverged too far to use BLASTn, we will use tBLASTx.  
Next, Exonerate is used to refine the BLAST results.  
These BLAST results are then given back to the gene prediction programs to produce improved gene models.  
Finally, the best gene models are chosen and quality control statistics are generated.  

13 hours later, we check to see if they all finished 
```bash
tail -n 45 OUTPUT*
```

Chunk|Finished?|Elapsed|Elapsed|User time|System time|try2 finished?|try2 Elapsed|try2 Elapsed|try2 User time|try2 System time|
---|---|---|---|---|---|---|---|---|---|---|
1|no|NA|13:00:28|2-01:00:16|55:00.948|yes|32670|09:04:56|4-16:11:18|41:42.061|
2|no|NA|13:00:28|30:57.525|15:41.211|yes|22038|06:07:46|3-05:59:32|33:16.219|
3|no|NA|13:00:25|5-10:23:28|02:07:51|yes|7375|02:03:23|16:02:08|05:51.186|
4|yes|41299|11:28:43|00:00:00|00:00:00|
5|yes|32097|08:55:21|5-04:51:35|02:06:47|
6|no|NA|13:00:25|5-10:12:36|02:06:17|yes|713|00:12:20|01:05:56|00:40.102|
7|yes|44500|12:22:04|7-00:03:17|02:53:30|
8|no|NA|13:00:25|4-07:23:58|01:49:08|yes|6502|01:48:48|14:13:42|05:17.076|
9|yes|39743|11:02:47|5-23:40:02|02:25:57|
10|yes|28312|07:52:17|00:00:00|00:00:00|
11|yes|34231|09:30:42|6-03:36:51|02:28:05|
12|yes|27863|07:44:34|4-23:08:42|01:58:15|
13|yes|28060|07:47:53|4-20:14:37|01:57:40|
14|yes|26459|07:21:11|4-00:01:07|01:46:12|
15|yes|23465|06:31:17|1-04:52:48|01:23:39|

Not all of them finished in the allotted time. That's ok, just retry the ones that did not finish. Maker does checkpointing so they should restart about where they left off. The commands must be the exact same.

```bash
sbatch Niagara_submitfile_Willisornismaker_chunk01.sh

sbatch Niagara_submitfile_Willisornismaker_chunk02.sh

sbatch Niagara_submitfile_Willisornismaker_chunk03.sh

sbatch Niagara_submitfile_Willisornismaker_chunk06.sh

sbatch Niagara_submitfile_Willisornismaker_chunk08.sh
```

They all finished during the second try, so I added those times into the table above.  
Now I am bringing the data back onto the main server to look at it.  

```bash
cd ~/Willisornis/maker/maker_R1
scp -r $USERNAME@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/* .
```

When I am working on maker on the server, I set up my environment like this:
```bash
conda activate maker

export PATH=$PATH:~/tools/ncbi-blast-2.9.0+/bin #add blast+ to your path so the executables can be found
export PATH=$PATH:~/tools/RepeatMasker 
export PATH=$PATH:~/tools/snap 
export PATH=~/tools/snap/Zoe:$PATH
export ZOE=/home/else/tools/snap/
export PATH=$PATH:~/tools
export PATH=$PATH:~/tools/RepeatMasker
export PATH=$PATH:~/tools/exonerate-2.2.0-x86_64/bin
export PATH=$PATH:~/tools/gm_et_linux_64/gmes_petap
export PATH=$PATH:~/tools/gm_et_linux_64/lib
export PATH=$PATH:~/tools/maker/bin
export PATH=$PATH:~/tools/blast-2.2.26/bin/
export PATH=$PATH:~/tools/tRNAscan-SE-2.0/bin/
export PATH=$PATH:~/tools/tRNAscan-SE-2.0/
export PATH=$PATH:/home/else/anaconda2/envs/Augustus/bin/
export PATH=$PATH:/home/else/tools/snoscan-0.9.1/squid-1.5.11/
export PATH=$PATH:/home/else/tools/snoscan-0.9.1/squid-1.5.11/Scripts/
export PATH=$PATH:/home/else/tools/snoscan-0.9.1/

~/perl5/perlbrew/bin/perlbrew switch perl-5.30.0
PERL5LIB=/home/else/perl5/lib/perl5/x86_64-linux/:$PERL5LIB

#or, on the other node:
#export PERLBREW_ROOT=/opt/perl5 #perlbrew will be installed in opt
#/opt/perl5/bin/perlbrew switch perl-5.30.0 #A sub-shell is launched with perl-5.30.0 as the activated perl. Run 'exit' to finish it.
export PATH=/opt/tools/maker/bin:$PATH

conda activate maker
```
Once maker finishes, check if there were any errors. It will list all the contigs, and if all went well, each will say STARTED and FINISHED (ones that are too small will say SKIPPED_SMALL and ones that failed will say DIED_SKIPPED_PERMANENT)
Then, merge all the contigs into single files.

```bash
cd ~/Willisornis/maker/maker_R1
#check that all contigs finished
less -S ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log

#check if there are any that failed and count how many were skipped vs finished
grep -c "SKIPPED_SMALL" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "STARTED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "FINISHED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "DIED_SKIPPED_PERMANENT" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #none! That is good
wc -l ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #just counting lines to make sure the preceeding numbers add up

#make sure that all of the contigs were run
grep -c "^>" Willisornis_input.fasta #Count contigs of original fasta file
cat Willisornis_input_0*.fasta | grep -c "^>" #Count input contigs of the many chunks - should add to the same number as the original above
cut -f 1 ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log | sort | uniq | wc -l #count number of unique contigs in the log (contigs that actually ran in the maker pipeline)

#If all looks good:

#Create files merging all data into a fasta and GFF3 file
time gff3_merge -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log> Willisornis_rnd1.all.maker.gff
time fasta_merge -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
#Create a gff3 file without sequences
time gff3_merge -n -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log > Willisornis_rnd1.all.maker.noseq.gff
#done
```
It is good I am so paranoid to count all the contigs - 7000 were missing when I first checked, and it turned out that the last of the 16 chunks (with 7000 small contigs) did not run! I caught the error in time to simply rerun that chunk before moving on, otherwise I would not have noticed and that whole part of the genome would not get annotated.

Attribute|#contigs (1st try)|#contigs (2nd try)|
---|---|---|
Input contigs|23,036|23,036|
Run contigs|16107|22,956|
SKIPPED_SMALL|15,030|21,145|
DIED_SKIPPED_PERMANENT|0|0|
STARTED|1069|1803|
FINISHED|1077|1811|
Total|17,176 lines|24,759 lines|

I do not know why 8 more contigs finished than started - it adds up that skipped + finished = total contigs, so I don't know why the start of a few were not recorded. Later I found out it is probably due to race conditions of having multiple threads accessing the same file. 

## Train SNAP

Now that we have run maker once, it will give us some gene models based on the protein/RNA evidence. This is not the finished product, but we will use it as a starting place to train the first gene prediction program, SNAP. Instructions for training SNAP are given by the program itself [here](https://github.com/KorfLab/SNAP) and also tips from Daren Card's Boa constrictor tutorial [here](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2). It is pretty quick, and so I am running it on the lab server rather than Scinet.

```bash
cd ~/Willisornis/maker/maker_R1
#prepare to train SNAP
mkdir snap
mkdir snap/round1
cd snap/round1

#convert the gff file to zff, while only including the most confident gene models
maker2zff -x 0.25 -l 50 -c 0 -e 0 -o 0.5 -d ../../Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
rename 's/genome/Willisornis_rnd1.zff.length50_aed0.25/g' *

#create statistics
fathom Willisornis_rnd1.zff.length50_aed0.25.ann Willisornis_rnd1.zff.length50_aed0.25.dna -gene-stats > gene-stats.log 2>&1
fathom Willisornis_rnd1.zff.length50_aed0.25.ann Willisornis_rnd1.zff.length50_aed0.25.dna -validate > validate.log 2>&1

#create the HMM file that SNAP requires for training, with the sequences and annotations with 1kb surrounding sequences
fathom -categorize 1000 Willisornis_rnd1.zff.length50_aed0.25.ann Willisornis_rnd1.zff.length50_aed0.25.dna > categorize.log 2>&1
fathom -export 1000 -plus uni.ann uni.dna > uni-plus.log 2>&1

#training parameters
mkdir params
cd params
forge ../export.ann ../export.dna > ../forge.log 2>&1
cd ..
#make the HMM file
time hmm-assembler.pl Willisornis_rnd1.zff.length50_aed0.25 params > Willisornis_rnd1.zff.length50_aed0.25.hmm
```
* Maker2zff `-x`: min AED score of genes to include (lower AED is better, AED of 1 are unsupported proteins.)
* Maker2zff `-l`: min length of genes to include -d: datastore file
* maker2zff `-c 0 -e 0`: these parameters control how much of a prediction's splice sites or exons must be confirmed by EST evidence to pass filters. Since we only have altest evidence from a different species, I set this to 0 since otherwise no proteins would pass filtering.
* maker2zff `-o 0.5`: this is a default value for how many of the exons must overlap protein or EST evidence to pass filtering
* Gff3_merge -d: "The location of the MAKER datastore index log file."
* Rename 's/old_word/new_word/g' *: searches all (*) filenames in the directory and replaces the old word with the new word

**Timing**:
All of the steps leading to hmm-assembler are very fast, taking only seconds or minutes each (on 1 thread). Then it seemed like it only took... 0.1s? Could this be right? The output looks right.

## Run Maker round 2
Save the progress of the RNA and protein alignments and the repeat annotation so that we don't need to repeat that part.
```bash
#RNA 
awk '{ if ($2 == "est2genome") print $0 }' Willisornis_rnd1.all.maker.noseq.gff > Willisornis_rnd1.all.maker.est2genome.gff
#protein
awk '{ if ($2 == "protein2genome") print $0 }' Willisornis_rnd1.all.maker.noseq.gff > Willisornis_rnd1.all.maker.protein2genome.gff
#repeats
awk '{ if ($2 ~ "repeat") print $0 }' Willisornis_rnd1.all.maker.noseq.gff > Willisornis_rnd1.all.maker.repeats.gff
```

Now go back to maker and change these lines in the options file
```bash
snaphmm=snap/round1/Willisornis_rnd1.zff.length50_aed0.25.hmm  
est2genome=0  
protein2genome=0  
altest_gff=Willisornis_rnd1.all.maker.est2genome.gff  
protein_gff=Willisornis_rnd1.all.maker.protein2genome.gff  

altest= #EST/cDNA sequence file in fasta format from an alternate organism
protein= #protein sequence file in fasta format (i.e. from mutiple oransisms)
```

Get the snap files
```bash
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R1/snap .
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R1/Willisornis_rnd1* .
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R1/Willisornis_input.all* .
scp -r else@$IP_ADDRESS:/home/else/Willisornis/RepeatMasking/Willisornis_repeat_library_cleaned_withFicalbUracya.lib .

find *Niagara_submitfile_Willisornismaker_chunk*.sh > tempfile
cat tempfile | while read line ; do sed 's/Round1/Round2/g' "$line" | sed 's/OUTPUT_R1/OUTPUT_R2/g' | sed 's/13:00:00/12:00:00/g' > R2_"$line" ; done
chmod +x R2_Niagara_submitfile*
mv maker_opts2.ctl maker_opts.ctl
```

Run again!
```bash
sbatch R2_Niagara_submitfile_Willisornismaker_chunk01.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk02.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk03.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk04.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk05.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk06.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk07.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk08.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk09.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk10.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk11.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk12.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk13.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk14.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk15.sh
sbatch R2_Niagara_submitfile_Willisornismaker_chunk16.sh
```

Get the data from Scinet back onto the server
```bash
mkdir ~/Willisornis/maker/maker_R2
cd ~/Willisornis/maker/maker_R2
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/OUTPUT* .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/Willisornis_input.maker.output . #this will take a while
```

Check to see if they all finished 
```bash
tail -n 45 OUTPUT*
```

Chunk|Finished?|Elapsed|Elapsed|User time|System time|
---|---|---|---|---|---|
1|yes|17858|04:58:07|22:08:30|03:42:26|
2|yes|14887|04:08:36|20:25:41|03:27:35|
3|yes|9524|02:39:13|12:10:47|01:56:32|
4|yes|7268|02:01:35|10:43:43|01:44:06|
5|yes|4908|01:22:14|07:46:44|01:20:52|
6|yes|9818|02:44:05|12:32:12|02:04:05|
7|yes|8302|02:18:49|10:34:02|01:44:10|
8|yes|11437|03:11:04|11:49:48|01:53:48|
9|yes|7214|02:00:41|09:08:08|01:27:07|
10|yes|4187|01:10:00|00:00:00|00:00:00|
11|yes|6034|01:40:47|09:00:33|01:27:34|
12|yes|4294|01:11:59|07:24:38|01:09:43|
13|yes|4163|01:09:49|00:00:00|00:00:00|
14|yes|4327|01:12:33|06:15:57|01:01:23|
15|yes|6480|01:48:25|04:04:48|01:01:54|
16|yes|7945|02:12:50|05:54:19|01:18:25|

There was this warning for chunk 13 but maker does appear to have finished successfully.
```
kernel messages produced during job executions:
[Dec 6 03:06] _ib_modify_qp: mlx5_0 rq_psn overflow, masking to 24 bits
[  +0.008372] _ib_modify_qp: mlx5_0 sq_psn overflow, masking to 24 bits
[  +0.008134] _ib_modify_qp: mlx5_0 rq_psn overflow, masking to 24 bits
[  +0.007984] _ib_modify_qp: mlx5_0 sq_psn overflow, masking to 24 bits
```

```bash
cd ~/Willisornis/maker/maker_R2

#check if there are any contigs that failed and count how many were skipped vs finished
grep -c "SKIPPED_SMALL" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "STARTED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "FINISHED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "DIED_SKIPPED_PERMANENT" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #none! That is good
wc -l ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #just counting lines to make sure the preceeding numbers add up

#make sure that all of the contigs were run (should be 23,036 contigs in the genome)
cut -f 1 ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log | sort | uniq | wc -l #count number of unique contigs in the log (contigs that actually ran in the maker pipeline)

#If all looks good:

#Create files merging all data into a fasta and GFF3 file
time gff3_merge -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log> Willisornis_rnd2.all.maker.gff
time fasta_merge -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
#Create a gff3 file without sequences
time gff3_merge -n -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log > Willisornis_rnd2.all.maker.noseq.gff
#done
```
**Timing:** gff3_merge: real	9m12.509s, user	0m35.044s, sys	0m9.980s; fasta_merge: real	1m55.420s, user	0m0.336s, sys	0m3.048s; gff3_merge -n: real	0m15.553s, user	0m12.728s, sys	0m2.740s.

Attribute|#contigs|
---|---|
Input contigs|23,036|
Run contigs|23,036|
SKIPPED_SMALL|21225|
DIED_SKIPPED_PERMANENT|0|
STARTED|1809|
FINISHED|1811|
Total|24,845 lines|

Unlike last time, this time the number of run cotigs actually matches the number of input contigs! I do not know why 2 more contigs finished than started - it adds up that skipped + finished = total contigs, so I don't know why the start of those two were not recorded, but I am not worrried about that.

## Train SNAP

Now that we have run maker again, we will have some gene models based on the protein/RNA evidence as well as the ab initio prediction by SNAP. This is not the finished product, as we will use it as a starting place again to train the SNAP to try to get a more refined HMM to predict the next round of genes. Instructions for training SNAP are given by the program itself [here](https://github.com/KorfLab/SNAP) and also tips from Daren Card's Boa constrictor tutorial [here](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2). It is pretty quick, and so I am running it on the lab server rather than Scinet.

```bash
cd ~/Willisornis/maker/maker_R2
#prepare to train SNAP
mkdir snap
mkdir snap/round2
cd snap/round2

#convert the gff file to zff, while only including the most confident gene models
time maker2zff -x 0.25 -l 50 -c 0 -e 0 -o 0.5 -d ../../Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
time rename 's/genome/Willisornis_rnd2.zff.length50_aed0.25/g' *

#create statistics
time fathom Willisornis_rnd2.zff.length50_aed0.25.ann Willisornis_rnd2.zff.length50_aed0.25.dna -gene-stats > gene-stats.log 2>&1
time fathom Willisornis_rnd2.zff.length50_aed0.25.ann Willisornis_rnd2.zff.length50_aed0.25.dna -validate > validate.log 2>&1

#create the HMM file that SNAP requires for training, with the sequences and annotations with 1kb surrounding sequences
time fathom -categorize 1000 Willisornis_rnd2.zff.length50_aed0.25.ann Willisornis_rnd2.zff.length50_aed0.25.dna > categorize.log 2>&1
time fathom -export 1000 -plus uni.ann uni.dna > uni-plus.log 2>&1

#training parameters
mkdir params
cd params
forge ../export.ann ../export.dna > ../forge.log 2>&1
cd ..
#make the HMM file
time hmm-assembler.pl Willisornis_rnd2.zff.length50_aed0.25 params > Willisornis_rnd2.zff.length50_aed0.25.hmm
```
* Maker2zff `-x`: max AED score of genes to include (lower AED is better, AED of 1 are unsupported proteins.)
* Maker2zff `-l`: min length of genes to include `-d `: datastore file
* maker2zff `-c 0 -e 0`: these parameters control how much of a prediction's splice sites or exons must be confirmed by EST evidence to pass filters. Since we only have altest evidence from a different species, I set this to 0 since otherwise no proteins would pass filtering.
* maker2zff `-o 0.5`: this is a default value for how many of the exons must overlap protein or EST evidence to pass filtering
* Gff3_merge -d: "The location of the MAKER datastore index log file."
* Rename 's/old_word/new_word/g' *: searches all (*) filenames in the directory and replaces the old word with the new word

**Timing**:
Maker2zff: real	1m31.868s, user	1m16.154s, sys	0m2.651s; rename 0.07s; gene-stats: real	0m27.508s, user	0m26.259s, sys	0m1.211s; validate: real	0m26.344s, user	0m25.320s, sys	0m0.996s; categorize: real	0m36.514s, user	0m31.012s, sys	0m3.763; export real	0m9.257s, user	0m6.854s, sys	0m1.521s; hmm-assembler: real	0m0.097s, user	0m0.030s, sys	0m0.009s. As you can see it is very fast.  

## Run Maker Round 3

### Control files
Change these lines again and run maker again:
```
snaphmm=snap/round2/Willisornis_rnd2.zff.length50_aed0.25.hmm  
augustus_species=chicken
#I tried these, but it did not wirk on scinet
#gmhmm=gmhmm.mod
#scoscan_rrna=Passeriformes_rRNA.fasta
#tRNA=1


model_org= #select a model organism for RepBase masking in RepeatMasker
rmlib= #provide an organism specific repeat library in fasta format for RepeatMasker
repeat_protein= #provide a fasta file of transposable element proteins for RepeatRunner
rm_gff=Willisornis_rnd1.all.maker.repeats.gff

#in the maker_exe.ctl file, to add Genemark (did not work in the end):
nano maker_exe.ctl
gmhmme3=/path/to/folder/tools/gm_et_linux_64/gmhmme3
probuild=/path/to/folder/tools/gm_et_linux_64/probuild

```

Move required data back onto Scinet and prepare batch jobs:

```bash
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R2/snap/round2 ./snap
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R2/Willisornis_rnd2.all.maker.repeats.gff .
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R2/gmhmm.mod .

find Niagara_submitfile_Willisornismaker_chunk*.sh > tempfile #list all the submitfiles
cat tempfile | while read line ; do sed 's/Round1/Round3/g' "$line" | sed 's/OUTPUT_R1/OUTPUT_R3/g' | sed 's/13:00:00/10:00:00/g' > R3_"$line" ; done #create round 3 submitfiles based on the list of submitfiles from round 1

chmod +x R3_Niagara_submitfile* #make submitfiles executable

#need to use sed to add these lines to all the batch files to make Genemark work (so that perl can find required modules installed in non-standard location)
sed -i '/libmpi.so/ a export PATH=$PATH:/path/to/folder/tools/gm_et_linux_64/' R3_Niagara_submitfile_Willisornismaker_chunk*.sh
sed -i '/OMP_NUM_THREADS=40/ a export PERL5LIB=$PERL5LIB:/path/to/folder/tools/perl/lib/perl5' R3_Niagara_submitfile_Willisornismaker_chunk*.sh
sed -i '/OMP_NUM_THREADS=40/ a export PERL5LIB=$PERL5LIB:/gpfs/fs0/path/to/folder/tools/tRNAscan-SE-2.0/lib' R3_Niagara_submitfile_Willisornismaker_chunk*.sh

sed -i '/module load augustus\/3.3/ a export AUGUSTUS_CONFIG_PATH=/gpfs/fs0/path/to/folder/tools/Augustus/config/' R3_Niagara_submitfile_Willisornismaker_chunk*.sh

sed -i '/module load augustus\/3.3/ a export PATH=/gpfs/fs0/path/to/folder/tools/Augustus/bin:/gpfs/fs0/path/to/folder/tools/Augustus/scripts:$PATH' R3_Niagara_submitfile_Willisornismaker_chunk*.sh

sed -i 's/10:00:00/00:59:00/g' R3_Niagara_submitfile_Willisornismaker_chunk*.sh


cp maker_opts3.ctl maker_opts.ctl #move the round 3 maker_opts.ctl to be the one used by maker

```

Sadly, Genemark-ES does not work on the scinet linux system and since the source code is not released I cannot just recompile it to work. It gets a segfault error which apparently happens on some Linus distributions. Very frustrating, I will have to drop it from the pipeline. So I have removed that part.

### Run Maker
```bash
sbatch R3_Niagara_submitfile_Willisornismaker_chunk01.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk02.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk03.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk04.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk05.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk06.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk07.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk08.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk09.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk10.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk11.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk12.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk13.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk14.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk15.sh
sbatch R3_Niagara_submitfile_Willisornismaker_chunk16.sh
```

Get the data back on the server:
```bash
mkdir ~/Willisornis/maker/maker_R3
cd ~/Willisornis/maker/maker_R3
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/OUTPUT_R3* .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/Willisornis_input.maker.output .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/maker_opts.ctl .
```

Once again, check that they all finished 
```bash
tail -n 45 OUTPUT*
```

I must admit, I accidentally used the old control file the first time I tried to do round 3: I did `cp maker_opts3.ctl maker_opts.ctl` but I did not notice it warned about overwriting the file and did not actually copy - so I essentially ran the exact same maker pipeline twice, but this time it took only 7 mins becaues it automatically detected that it was the exact same maker command being run and there was nothing left to do. Here is how fast it went when it did not have to do anything:

Chunk|Finished?|Elapsed|Elapsed|User time|System time|
---|---|---|---|---|---|
1|yes|125|00:03:26|00:05.933|00:03:26|
2|yes|195|00:03:27|00:06.107|00:03:27|
3|yes|198|00:03:31|00:00:00|00:00:00|
4|yes|196|00:03:28|00:05.865|00:03.921|
5|yes|194|00:03:26|00:05.690|00:03.864|
6|yes|127|00:02:20|00:05.673|00:03.967|
7|yes|128|00:02:21|00:05.731|00:03.918|
8|yes|126|00:02:19|00:05.951|00:03.794|
9|yes|6|00:00:29|00:05.580|00:03.757|
10|yes|198|00:03:31|00:00:00|00:00:00|
11|yes|48|00:01:01|00:05.704|00:03.857|
12|yes|196|00:03:28|00:05.879|00:04.253|
13|yes|54|00:01:07|00:05.642|00:03.929|
14|yes|394|00:06:47|00:00:00|00:00:00|
15|yes|350|00:06:01|01:52.800|02:28.525|
16|yes|178|00:03:08|01:09.137|01:31.575|

Here is how long it really took after I fixed the error (running SNAP, & Augustus):
Chunk|Finished?|Elapsed|Elapsed|User time|System time|Finished?|Elapsed|Elapsed|User time|System time|
---|---|---|---|---|---|---|---|---|---|---|
1|yes|2608|00:43:46|01:08:59|06:00.147|
2|No|195|00:59:19|01:55:51|08:34.031|yes|1045|00:17:44|16:32.052|00:44.256|
3|yes|1968|00:33:03|01:21:20|06:52.816|
4|yes|1823|00:30:35|01:21:26|06:05.228|
5|yes|1060|00:18:02|01:04:52|04:26.233|
6|yes|2856|00:47:53|01:41:20|00:47:53|
7|yes|2093|00:35:08|01:26:12|00:35:08|
8|yes|3236|00:54:11|01:46:40|00:54:11|
9|yes|1881|00:31:35|00:00:00|00:00:00|
10|yes|1132|00:19:12|01:00:28|03:46.691|
11|?|1785|00:30:04|01:21:51|04:48.278|
12|yes|1128|00:19:07|03:48.566|03:48.566|
13|yes|1211|00:20:25|01:03:39|03:45.910|
14|yes|1425|00:24:03|01:05:37|05:00.017|
15|yes|959|00:16:13|27:53.291|05:30.119|
16|yes|1151|00:19:25|49:04.759|05:38.806|

The batch 2 did not finish in the allotted 59 mins so I had to rerun it, it needed an extra 17 mins.

Assess results:
```bash
cd ~/Willisornis/maker/maker_R3
export PERLBREW_ROOT=/opt/perl5 #perlbrew is installed in opt
/opt/perl5/bin/perlbrew switch perl-5.30.0 #A sub-shell is launched with perl-5.30.0 as the activated perl. Run 'exit' to finish it.
export PATH=/opt/tools/maker/bin:$PATH #working on the Troglodytes node

#check if there are any contigs that failed and count how many were skipped vs finished
grep -c "SKIPPED_SMALL" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "STARTED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "FINISHED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "DIED_SKIPPED_PERMANENT" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #none! That is good
wc -l ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #just counting lines to make sure the preceeding numbers add up

#make sure that all of the contigs were run (should be 23,036 contigs in the genome)
cut -f 1 ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log | sort | uniq | wc -l #count number of unique contigs in the log (contigs that actually ran in the maker pipeline)

#If all looks good:

#Create files merging all data into a fasta and GFF3 file
time gff3_merge -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log> Willisornis_rnd3.all.maker.gff
time fasta_merge -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
#Create a gff3 file without sequences
time gff3_merge -n -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log > Willisornis_rnd3.all.maker.noseq.gff
#done
```
**Timing:** less than 37s per merge command.

Attribute|#contigs (round 2)|#contigs (round 3)|
---|---|---|
Input contigs|23,036|23,036|
Run contigs|23,036|23,036|
SKIPPED_SMALL|21,225|21,225|
DIED_SKIPPED_PERMANENT|0|0|
STARTED|1809|1812|
FINISHED|1811|1811|
Lines|24,845 lines|24,848 lines|


## Train SNAP again

Now that we have run maker again, we will have some gene models based on the protein/RNA evidence as well as the ab initio prediction by SNAP. This is not the finished product, as we will use it as a starting place again to train the SNAP to try to get a more refined HMM to predict the next round of genes. Instructions for training SNAP are given by the program itself [here](https://github.com/KorfLab/SNAP) and also tips from Daren Card's Boa constrictor tutorial [here](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2). It is pretty quick, and so I am running it on the lab server rather than Scinet.

```bash
cd ~/Willisornis/maker/maker_R3
#prepare to train SNAP
mkdir snap
mkdir snap/round3
cd snap/round3

#convert the gff file to zff, while only including the most confident gene models
time maker2zff -x 0.25 -l 50 -c 0 -e 0 -o 0.5 -d ../../Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
time rename 's/genome/Willisornis_rnd3.zff.length50_aed0.25/g' *

#create statistics
time fathom Willisornis_rnd3.zff.length50_aed0.25.ann Willisornis_rnd3.zff.length50_aed0.25.dna -gene-stats > gene-stats.log 2>&1
time fathom Willisornis_rnd3.zff.length50_aed0.25.ann Willisornis_rnd3.zff.length50_aed0.25.dna -validate > validate.log 2>&1

#create the HMM file that SNAP requires for training, with the sequences and annotations with 1kb surrounding sequences
time fathom -categorize 1000 Willisornis_rnd3.zff.length50_aed0.25.ann Willisornis_rnd3.zff.length50_aed0.25.dna > categorize.log 2>&1
time fathom -export 1000 -plus uni.ann uni.dna > uni-plus.log 2>&1

#training parameters
mkdir params
cd params
forge ../export.ann ../export.dna > ../forge.log 2>&1
cd ..
#make the HMM file
time hmm-assembler.pl Willisornis_rnd3.zff.length50_aed0.25 params > Willisornis_rnd3.zff.length50_aed0.25.hmm
#done
```
* Maker2zff `-x`: max AED score of genes to include (lower AED is better, AED of 1 are unsupported proteins.)
* Maker2zff `-l`: min length of genes to include `-d `: datastore file
* maker2zff `-c 0 -e 0`: these parameters control how much of a prediction's splice sites or exons must be confirmed by EST evidence to pass filters. Since we only have altest evidence from a different species, I set this to 0 since otherwise no proteins would pass filtering.
* maker2zff `-o 0.5`: this is a default value for how many of the exons must overlap protein or EST evidence to pass filtering
* Gff3_merge -d: "The location of the MAKER datastore index log file."
* Rename 's/old_word/new_word/g' *: searches all (*) filenames in the directory and replaces the old word with the new word

Move required data back onto Scinet and prepare batch jobs:

```bash
scp -r else@$IP_ADDRESS:/home/else/Willisornis/maker/maker_R3/snap/round3 ./snap

find Niagara_submitfile_Willisornismaker_chunk*.sh > tempfile #list all the submitfiles
cat tempfile | while read line ; do sed 's/Round3/Round4/g' R3_"$line" | sed 's/OUTPUT_R3/OUTPUT_R4/g' > R4_"$line" ; done #create round 4 submitfiles based on the list of submitfiles from round 3
chmod +x R4_Niagara_submitfile_Willisornismaker_chunk*.sh

nano maker_opts.ctl
#keep_preds=1 #yes I am desperate
#snap hmm changed to round 3 hmm
```
### Run Maker again
```bash
sbatch R4_Niagara_submitfile_Willisornismaker_chunk01.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk02.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk03.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk04.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk05.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk06.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk07.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk08.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk09.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk10.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk11.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk12.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk13.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk14.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk15.sh
sbatch R4_Niagara_submitfile_Willisornismaker_chunk16.sh
```
Check results:

```bash
#check if there are any that failed and count how many were skipped vs finished
grep -c "SKIPPED_SMALL" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "STARTED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "FINISHED" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log 
grep -c "DIED_SKIPPED_PERMANENT" ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #none! That is good
wc -l ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log #just counting lines to make sure the preceeding numbers add up

#make sure that all of the contigs were run
grep -c "^>" Willisornis_input.fasta #Count contigs of original fasta file
cat Willisornis_input_0*.fasta | grep -c "^>" #Count input contigs of the many chunks - should add to the same number as the original above
cut -f 1 ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log | sort | uniq | wc -l #count number of unique contigs in the log (contigs that actually ran in the maker pipeline)

#If all looks good:

#Create files merging all data into a fasta and GFF3 file
time gff3_merge -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log> Willisornis_rnd4.all.maker.gff
time fasta_merge -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
#Create a gff3 file without sequences
time gff3_merge -n -s -d ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log > Willisornis_rnd4.all.maker.noseq.gff
#done
```
Attribute|#contigs (round 2)|#contigs (round 3)|
---|---|---|
Input contigs|23,036|23,036|23,036|
Run contigs|23,036|23,036|23,036|
SKIPPED_SMALL|21,225|21,225|21,225|
DIED_SKIPPED_PERMANENT|0|0|0
STARTED|1809|1812|1875|
FINISHED|1811|1811|1811|
Lines|24,845 lines|24,848 lines|24,911|

Get the data back on the server:
```bash
mkdir ~/Willisornis/maker/maker_R4
cd ~/Willisornis/maker/maker_R4
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/OUTPUT_R4* .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/Willisornis_input.maker.output .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/maker_opts.ctl .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/Willisornis_rnd4.all.mak*.gff .
scp -r elsemikk@niagara.scinet.utoronto.ca:/path/to/folder/0_MAKER/Willisornis/Willisornis_input*.fasta .
```

Once again, check that they all finished. It took a couple times for each to finish as they timed out.
```
tail -n 45 OUTPUT*
```

Later, I found that the status can also be examined with this nice script from GAAS:
```bash
cd ~/Willisornis/maker/maker_R4

~/perl5/perlbrew/bin/perlbrew switch perl-5.30.0
PERL5LIB=/home/else/perl5/lib/perl5/x86_64-linux/:$PERL5LIB
#OR
#export PERL5LIB=$PERL5LIB:/home/0_PROGRAMS/GAAS/annotation
#export PATH=${PATH}:/home/0_PROGRAMS/GAAS/annotation/Tools/bin

/home/0_PROGRAMS/GAAS/annotation/Tools/Maker/maker_check_progress.sh ./Willisornis_input.maker.output/Willisornis_input_master_datastore_index.log
```

## Evaluate results

I would like to compare the results of the three rounds and see a general sense of how "good" the annotation might be.  

Round 1: based only on alt-EST and protein evidence  
Round 2: based on SNAP trainied on Round 1
Round 3: based on SNAP trained on Round 2 + Augustus trained on chicken
Round 4: based on SNAP trained on Round 3 + Augustus trained on chicken + keep_preds option

Firstly, how many genes do we have? How long are they on average? (script by [Darren Card](https://gist.github.com/darencard/bb1001ac1532dd4225b030cf0cd61ce2).)
```bash
cd ~/Willisornis/maker
#Round1
cat maker_R1/Willisornis_rnd1.all.maker.gff | awk '{ if ($3 == "gene") print $0 }' | awk '{ sum += ($5 - $4) } END { print NR, sum / NR }'
#Round2
cat maker_R2/Willisornis_rnd2.all.maker.gff | awk '{ if ($3 == "gene") print $0 }' | awk '{ sum += ($5 - $4) } END { print NR, sum / NR }'
#Round3
cat maker_R3/Willisornis_rnd3.all.maker.gff | awk '{ if ($3 == "gene") print $0 }' | awk '{ sum += ($5 - $4) } END { print NR, sum / NR }'
#Round4
cat maker_R4/Willisornis_rnd4.all.maker.gff | awk '{ if ($3 == "gene") print $0 }' | awk '{ sum += ($5 - $4) } END { print NR, sum / NR }'

```

Round|# Genes|Average Length|
---|---|---|
1|13,112|10,629.8|
2|17,064|25,944.5|
3|14,578|16,824.3|
4|43,959|29,709|

Secondly, how complete is our proteome? We can measure this using BUSCO
```bash
#set up folders
cd ~/Willisornis/maker
mkdir busco
cd ~/Willisornis/maker/busco

#get config file. Edit if needed (make sure paths to prerequisite programs are correct. Mt default also has tblastn not forced to single threaded, and augustus species is chicken).
cp /home/0_PROGRAMS/busco/config/config.ini ./Willisornis_busco_config.ini

#set up environment
conda activate Augustus #has augustus installed
export BUSCO_CONFIG_FILE="/hhome/else/Willisornis/maker/busco/Willisornis_busco_config.ini"

#Run BUSCO!
#assess transcripts
time python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R1/Willisornis_input.all.maker.transcripts.fasta  -o R1_tranannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m transcriptome -c 24 -sp chicken -z --augustus_parameters='--progress=true'

time python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R2/Willisornis_input.all.maker.transcripts.fasta  -o R2_tranannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m transcriptome -c 24 -sp chicken -z --augustus_parameters='--progress=true'

time python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R3/Willisornis_input.all.maker.transcripts.fasta  -o R3_tranannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m transcriptome -c 24 -sp chicken -z --augustus_parameters='--progress=true'

#assess proteins
python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R1/Willisornis_input.all.maker.proteins.fasta  -o R1_protannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'

python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R2/Willisornis_input.all.maker.proteins.fasta  -o R2_protannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'

python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R3/Willisornis_input.all.maker.proteins.fasta  -o R3_protannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'


#check ab initio predictions to compare
python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R3/Willisornis_input.all.maker.non_overlapping_ab_initio.proteins.fasta  -o DumpsterDive -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'

cat ../maker_R3/Willisornis_input.all.maker.non_overlapping_ab_initio.proteins.fasta ../maker_R3/Willisornis_input.all.maker.proteins.fasta > ../maker_R3/Dumpster.fasta

python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R3/Dumpster.fasta  -o FullDumpsterDive -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'

#round 4
python /home/0_PROGRAMS/busco/scripts/run_BUSCO.py -i ../maker_R4/Willisornis_input.all.maker.proteins.fasta  -o R4_protannotation_eval -l /home/0_PROGRAMS/busco/aves_odb9 -m proteins -c 24 -sp chicken -z --augustus_parameters='--progress=true'

```
* `-m`: assessment mode (genome, transcriptome, or proteins)
* `-l /home/0_PROGRAMS/busco/aves_odb9`: path to the lineage file of gene models (this ones is for birds)
* `-i Willisornis.fasta`: input sequence
* `-o R1_annotation_eval`: output prefix
* `-c 24`: number of cores to use
* `-sp chicken`: Augustus gene model to use. chicken is the only bird currently available.
* `-z`: tarzip the output files

**Results**:

BUSCO run|#genes|total BUSCOs|complete BUSCOs|complete single-copy BUSCOS|complete duplicated BUSCOS|fragmented BUSCOS|missing BUSCOS|run time (s)|
|---|---|---|---|---|---|---|---|---|
Genome|?|96.7%|C:91.6%|S:90.1%|D:1.5%|F:5.1%|M:3.3%|15862.3|
Maker round 1 (transcripts)|13,112|91.1%|C:76.2%|S:75.0%|D:1.2%|F:14.9%|M:8.9%|988.9|
Maker round 2 (transcripts)|17,064|86.7%|C:70.7%|S:69.9%|D:0.8%|F:16.0%|M:13.3%|1132.6|
Maker round 3 (transcripts)|14,578|88.2%|C:75.8%|S:74.7%|D:1.1%|F:12.4%|M:11.8%|2179.1|
Maker round 1 (proteins)|13,112|91.1%|C:76.2%|S:74.9%|D:1.3%|F:14.9%|M:8.9%|156.5|
Maker round 2 (proteins)|17,064|86.6%|C:70.2%|S:69.3%|D:0.9%|F:16.4%|M:13.4%|167.6|
Maker round 3 (proteins)|14,578|88.2%|C:75.8%|S:74.6%|D:1.2%|F:12.4%|M:11.8%|383.5|
Maker round 3  (garbage)|37,516| 5.4%|C:3.8%|S:3.7%|D:0.1|F:1.6%|M:94.6%|75.63|
Maker round 3 (garbage+)|52,094|92% |C:78.8%|S:77.5%|D:1.3|F:13.2%|M:8.0%|205.0|
Maker round 4 (proteins)|43,959|93% |C:80.1%|S:78.7%|D:1.4|F:12.9%|M:7.0%|207.7|

88.2+3.8+1.6=93.6... better...
INFO	C:70.7%[S:69.9%,D:0.8%],F:16.0%,M:13.3%,n:4915
INFO	3475 Complete BUSCOs (C)
INFO	3435 Complete and single-copy BUSCOs (S)
INFO	40 Complete and duplicated BUSCOs (D)
INFO	786 Fragmented BUSCOs (F)
INFO	654 Missing BUSCOs (M)
INFO	4915 Total BUSCO groups searched
INFO	BUSCO analysis done with WARNING(s). Total running time: 1132.55941796 seconds
INFO	Results written in /hhome/else/Willisornis/maker/busco/run_R1_tranannotation_eval/


Now, visualize the distribution of AED scores: you want as many to be close to 0 as possible
```bash
cd ~/Willisornis/maker
perl /home/0_PROGRAMS/Genome_annotation/AED_cdf_generator.pl -b 0.025 maker_R1/Willisornis_rnd1.all.maker.gff maker_R2/Willisornis_rnd2.all.maker.gff maker_R3/Willisornis_rnd3.all.maker.gff maker_R4/Willisornis_rnd4.all.maker.gff > AED_cdf_distributions.txt
```
* `-b`: bin size

Another assessment can be done with this script to get info on stats:
```bash
cd ~/Willisornis/maker
export PERLBREW_ROOT=/opt/perl5
/opt/perl5/bin/perlbrew switch perl-5.30.0 #A sub-shell is launched with perl-5.30.0 as the activated perl. Run 'exit' to finish it.
export PERL5LIB=$PERL5LIB:/hhome/else/.conda/envs/agat/lib/site_perl/5.26.2/

conda activate agat
agat_sp_functional_statistics.pl --gff ./maker_R1/Willisornis_rnd1.all.maker.noseq.gff -o ./maker_R1/Willisornis_rnd1__genestats
agat_sp_functional_statistics.pl --gff ./maker_R2/Willisornis_rnd2.all.maker.noseq.gff -o ./maker_R2/Willisornis_rnd2_genestats
agat_sp_functional_statistics.pl --gff ./maker_R3/Willisornis_rnd3.all.maker.noseq.gff -o ./maker_R3/Willisornis_rnd3_genestats
agat_sp_functional_statistics.pl --gff ./maker_R4/Willisornis_rnd4.all.maker.noseq.gff -o ./maker_R4/Willisornis_rnd4_genestats
```

The `agat_sp_functional_statistics` results and CDF distributions are in the Annotation_stats folder of this repository.
All the maker control files are in the Maker_controlfiles folder.

## Note on Augustus:
I have opted not to train Augustus for my own genomes, because:
1) Augustus takes a very long time to train and the project deadlines make it impractical to train a Augustus with a dozen different genomes, since there are students waiting to analyze the results.
2) Augustus has already be trained on chicken. I think these gene models are probably quite high quality since a lot of effort has gone into these model organisms. The chicken gene models are probably better than what I could produce easily for a non-model species that do not even have RNA-seq data.
4) According to "[Predicting Genes in Single Genomes with AUGUSTUS](https://currentprotocols.onlinelibrary.wiley.com/doi/full/10.1002/cpbi.57)" (Current Protocols in Bioinformatics), even when predicting genes in zebrafish with the chicken models (instead of zebrafish models), sensitivity only dropped from 80.2 to 73.6 and specificity from 71.0 to 66.1. If the difference was not that big when using chicken for a fish, then it should be just fine to use on most birds probably.
5) "As a rule of thumb, retraining for B is not necessary if A and B are so closely related that their genomes can be aligned with each other at least in most coding regions (e.g., the average protein sequence alignment has >70% identities, as in human and mouse, for example)." Chicken does align to passeriformes with BLASTp, and with BLASTn with around 82% identity when I did just a quick check.

